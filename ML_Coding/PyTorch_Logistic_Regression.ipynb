{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54617ce2-15c5-43c7-8948-5f66b52e1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n",
    "# https://jovian.ai/aakashns/02-linear-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595ca218-f16d-4ade-a065-74c5b4657a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Implementation - https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_logistic_regression/#building-a-logistic-regression-model-with-pytorch-gpu\n",
    "# https://towardsdatascience.com/logistic-regression-with-pytorch-3c8bbea594be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dedc8bb-729e-403a-99c1-9a46646cfddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n"
     ]
    }
   ],
   "source": [
    "#!python --version\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25be20f5-07fc-4e77-8118-cec0030ece1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from numpy import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d6bee5-daf9-4759-bc52-b1b0072f3ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[406, 217, 935, 629, 214, 517, 938, 586, 733, 625],\n",
       "       [214, 769, 798, 974,  62, 872, 596, 865, 192, 694],\n",
       "       [881, 390, 565, 731, 383, 346, 328, 807, 705, 241],\n",
       "       [547, 975,  98, 782, 445, 101, 202, 703, 564, 648],\n",
       "       [999, 108, 157, 552, 306, 790, 408, 487, 784, 670],\n",
       "       [436, 831, 137, 427, 585,  65, 425, 881, 380, 612],\n",
       "       [928, 397,  91, 488,  48, 947, 159, 824,  83, 699],\n",
       "       [714,  78, 750, 146,  53, 200, 882, 322, 299, 801],\n",
       "       [607, 560, 958, 729, 577, 292, 902, 645, 422, 768],\n",
       "       [406, 709, 110, 760, 325, 836,  78, 185, 971, 406]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = random.randint(1000, size=(100,10))\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a29d0a1-5367-4fd5-a780-7318b2551a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = random.randint(2, size=(100,1))\n",
    "y [:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af2d048-b1f9-433d-952e-b26e13b2b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp to convert to \"float\" tensor\n",
    "X = torch.from_numpy(X).to(torch.float32)\n",
    "y = torch.from_numpy(y).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa0abb5-7404-475b-ba8e-92f7426e320b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[406., 217., 935., 629., 214., 517., 938., 586., 733., 625.],\n",
       "         [214., 769., 798., 974.,  62., 872., 596., 865., 192., 694.],\n",
       "         [881., 390., 565., 731., 383., 346., 328., 807., 705., 241.]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [0.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll create a TensorDataset, which allows access to rows from X and y as tuples, and provides standard APIs for working \n",
    "# with many different types of datasets in PyTorch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_ds = TensorDataset(X, y)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897c0ca9-4c7e-43c9-a8b5-50fb0c15bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader (DataLoader can split the data into batches of a predefined size while training)\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce280aa-0a0d-4906-a308-b88cda41e938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[881., 390., 565., 731., 383., 346., 328., 807., 705., 241.],\n",
      "        [668.,  16., 401., 159., 494., 506., 634., 724., 129., 907.],\n",
      "        [676., 121., 244., 769., 288., 183., 423., 570., 643., 355.],\n",
      "        [402., 820., 619., 456., 727., 681., 797., 129., 934., 429.],\n",
      "        [  6., 209., 228., 515., 630., 528., 822.,  46., 799.,  52.]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "# Provides data in batch size of 5\n",
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e6238e8-70b4-42bf-8216-3fcdc817cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Class and instantiate it\n",
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegression(nn.Module):    \n",
    "    # build the constructor\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_inputs, n_outputs)\n",
    "    # make predictions\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))  # note the sigmoid transformation\n",
    "        return y_pred\n",
    "\n",
    "input_dim = 10\n",
    "output_dim = 1    \n",
    "\n",
    "model = LogisticRegression(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43680a9d-892a-4601-9108-e69232d6887f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1634, -0.2264, -0.0220,  0.2848, -0.0691, -0.0577, -0.1802,  0.0483,\n",
       "           0.2846,  0.2539]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0959], requires_grad=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e55c6a2b-7ef5-404f-8e60-0e3b8312c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss fn \n",
    "criterion = nn.BCELoss()  # binary cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac62a7a-c7d0-4fc2-977d-d3cc984c0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1633010d-5df3-4ac2-b7bc-92ecf9d4e6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Loss = 60.0\n",
      "Epoch = 1, Loss = 80.0\n",
      "Epoch = 2, Loss = 40.0\n",
      "Epoch = 3, Loss = 60.0\n",
      "Epoch = 4, Loss = 20.0\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "for epoch in range(5):\n",
    "    # enumerate mini batches\n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # compute the model output\n",
    "        yhat = model(inputs)\n",
    "        # calculate loss\n",
    "        loss = criterion(yhat, targets)\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # update model weights using gradient\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoch = {}, Loss = {}'.format(epoch, loss.item()))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "002aa262-44bb-422d-8e81-783913ba22eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions/inference\n",
    "preds = model(X[:10])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a1c5c3f-d931-4fa4-8a29-346ab0053ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "\n",
    "torch.save(model.state_dict(), 'pytorch_logistic_regression_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59c804-f4b5-4854-806d-21e118b95b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
